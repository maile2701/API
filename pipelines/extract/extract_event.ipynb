{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4) (4.15.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.12/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ah2aG0qgxCex"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "owfl3QDVgA-e"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://vi.wikipedia.org/wiki/Ch%C3%B9a_Thi%C3%AAn_M%E1%BB%A5\",\n",
        "    \"https://vi.wikipedia.org/wiki/C%E1%BB%91_%C4%91%C3%B4_Hu%E1%BA%BF\",\n",
        "    \"https://vi.wikipedia.org/wiki/L%C4%83ng_Gia_Long\",\n",
        "    \"https://vi.wikipedia.org/wiki/L%C4%83ng_Minh_M%E1%BA%A1ng\",\n",
        "    \"https://vi.wikipedia.org/wiki/L%C4%83ng_T%E1%BB%B1_%C4%90%E1%BB%A9c\",\n",
        "    \"https://vi.wikipedia.org/wiki/Tr%E1%BA%ADn_C%E1%BB%ADa_Thu%E1%BA%ADn_An\",\n",
        "    \"https://vi.wikipedia.org/wiki/Phong_tr%C3%A0o_C%E1%BA%A7n_V%C6%B0%C6%A1ng\",\n",
        "    \"https://vi.wikipedia.org/wiki/C%E1%BA%A7u_Tr%C6%B0%E1%BB%9Dng_Ti%E1%BB%81n\",\n",
        "    \"https://vi.wikipedia.org/wiki/V%E1%BB%A5_m%C6%B0u_kh%E1%BB%9Fi_ngh%C4%A9a_%E1%BB%9F_Hu%E1%BA%BF_(1916)\",\n",
        "    \"https://vi.wikipedia.org/wiki/S%E1%BB%B1_ki%E1%BB%87n_T%E1%BA%BFt_M%E1%BA%ADu_Th%C3%A2n\",\n",
        "    \"https://vi.wikipedia.org/wiki/Festival_Hu%E1%BA%BF\"\n",
        "]\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "filepath = \"/Users/thanhmai/etl_pipeline test/data/wiki_data_Hue.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "pDIip7-gkayD"
      },
      "outputs": [],
      "source": [
        "with open(filepath, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"T√™n trang\", \"Thu·ªôc t√≠nh\", \"Gi√° tr·ªã\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "weMWI6WUnYNt"
      },
      "outputs": [],
      "source": [
        "def crawl_wiki(url):\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    # --- T√™n trang ---\n",
        "    title_tag = soup.find(\"h1\", id=\"firstHeading\")\n",
        "    title = title_tag.text.strip() if title_tag else \"Kh√¥ng r√µ ti√™u ƒë·ªÅ\"\n",
        "    rows = []\n",
        "    # --- Crawl Infobox ---\n",
        "    infobox = soup.find(\"table\", class_=lambda x: x and \"infobox\" in x)\n",
        "    if infobox:\n",
        "        for row in infobox.find_all(\"tr\"):\n",
        "            label = row.find(\"th\")\n",
        "            value = row.find(\"td\")\n",
        "            if label and value:\n",
        "                key = label.get_text(\" \", strip=True)\n",
        "                val = value.get_text(\" \", strip=True)\n",
        "                rows.append([title, key, val])\n",
        "    # --- Crawl ph·∫ßn \"L·ªãch s·ª≠\" ho·∫∑c \"H√¨nh th√†nh\" ---\n",
        "    description = \"\"\n",
        "    for header in soup.find_all([\"h2\", \"h3\"]):\n",
        "        section_title = header.get_text(\" \", strip=True).lower()\n",
        "        if any(keyword in section_title for keyword in [\"l·ªãch s·ª≠\", \"h√¨nh th√†nh\", \"kh·ªüi l·∫≠p\", \"qu√° tr√¨nh x√¢y d·ª±ng\"]):\n",
        "            content = []\n",
        "            for sibling in header.find_next_siblings():\n",
        "                if sibling.name in [\"h2\", \"h3\"]:\n",
        "                    break\n",
        "                if sibling.name == \"p\":\n",
        "                    content.append(sibling.get_text(\" \", strip=True))\n",
        "            description = \"\\n\".join(content).strip()\n",
        "            break\n",
        "    if not description and infobox:\n",
        "        first_p_after_infobox = None\n",
        "        # L·∫∑p qua c√°c th·∫ª sau infobox ƒë·ªÉ t√¨m th·∫ª <p> ƒë·∫ßu ti√™n\n",
        "        for sibling in infobox.find_next_siblings():\n",
        "            if sibling.name == 'p':\n",
        "                first_p_after_infobox = sibling\n",
        "                break # ƒê√£ t√¨m th·∫•y\n",
        "        if first_p_after_infobox:\n",
        "            description = first_p_after_infobox.get_text(\" \", strip=True)\n",
        "    if not description:\n",
        "        first_p = soup.find(\"p\")\n",
        "        if first_p:\n",
        "            description = first_p.get_text(\" \", strip=True)\n",
        "    # L√†m s·∫°ch k√Ω hi·ªáu [1], [2], [3]\n",
        "    for j in range(1, 500):\n",
        "        description = description.replace(f\"[{j}]\", \"\")\n",
        "    # Ghi d·ªØ li·ªáu\n",
        "    rows.append([title, \"M√¥ t·∫£\", description])\n",
        "    with open(filepath, \"a\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(rows)\n",
        "    print(f\"‚úÖ ƒê√£ l∆∞u {title} ({len(rows)} d√≤ng).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5AYh9p3ncQm",
        "outputId": "3eae689c-0e57-4e62-97c5-1168fcdb37e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ƒê√£ l∆∞u Ch√πa Thi√™n M·ª• (8 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u C·ªë ƒë√¥ Hu·∫ø (4 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u LƒÉng Gia Long (6 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u LƒÉng Minh M·∫°ng (6 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u LƒÉng T·ª± ƒê·ª©c (7 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u Tr·∫≠n C·ª≠a Thu·∫≠n An (5 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u Phong tr√†o C·∫ßn V∆∞∆°ng (5 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u C·∫ßu Tr∆∞·ªùng Ti·ªÅn (14 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u V·ª• m∆∞u kh·ªüi nghƒ©a ·ªü Hu·∫ø (1916) (5 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u S·ª± ki·ªán T·∫øt M·∫≠u Th√¢n (5 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u Festival Hu·∫ø (1 d√≤ng).\n",
            "\n",
            "üéâ Ho√†n t·∫•t! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u trong file: /Users/thanhmai/etl_pipeline test/data/wiki_data_Hue.csv\n"
          ]
        }
      ],
      "source": [
        "for url in urls:\n",
        "    try:\n",
        "        crawl_wiki(url)\n",
        "        time.sleep(2)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå L·ªói khi crawl {url}: {e}\")\n",
        "\n",
        "print(f\"\\nüéâ Ho√†n t·∫•t! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u trong file: {filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2Z7CLDz-5dOh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/Users/thanhmai/etl_pipeline test/data/wiki_data_Hue.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAo-EHaG5oT1",
        "outputId": "945eb941-6789-41ec-e2d2-0677c7e9469a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ƒê√£ ƒë·ªçc file '/Users/thanhmai/etl_pipeline test/data/wiki_data_Hue.csv' th√†nh c√¥ng ---\n",
            "\n",
            "==============================\n",
            "\n",
            "--- D·ªÆ LI·ªÜU ƒê√É CHU·∫®N H√ìA (HO√ÄN CH·ªàNH) ---\n",
            "                        event_name  \\\n",
            "0                    Ch√πa Thi√™n M·ª•   \n",
            "1                  C·∫ßu Tr∆∞·ªùng Ti·ªÅn   \n",
            "2                        C·ªë ƒë√¥ Hu·∫ø   \n",
            "3                     Festival Hu·∫ø   \n",
            "4                    LƒÉng Gia Long   \n",
            "5                   LƒÉng Minh M·∫°ng   \n",
            "6                      LƒÉng T·ª± ƒê·ª©c   \n",
            "7             Phong tr√†o C·∫ßn V∆∞∆°ng   \n",
            "8             S·ª± ki·ªán T·∫øt M·∫≠u Th√¢n   \n",
            "9                Tr·∫≠n C·ª≠a Thu·∫≠n An   \n",
            "10  V·ª• m∆∞u kh·ªüi nghƒ©a ·ªü Hu·∫ø (1916)   \n",
            "\n",
            "                                          description  \\\n",
            "0   M√¥ t·∫£: Ch√πa Thi√™n M·ª• hay c√≤n g·ªçi l√† ch√πa Linh ...   \n",
            "1   M√¥ t·∫£: C·∫ßu Tr∆∞·ªùng Ti·ªÅn hay c·∫ßu Tr√†ng Ti·ªÅn [ 1 ...   \n",
            "2   M√¥ t·∫£: C·ªë ƒë√¥ Hu·∫ø , c√≤n g·ªçi l√† Ph√∫ Xu√¢n , l√† th...   \n",
            "3   M√¥ t·∫£: Festival Hu·∫ø ƒë∆∞·ª£c t·ªï ch·ª©c 2 nƒÉm m·ªôt l·∫ßn...   \n",
            "4   M√¥ t·∫£: LƒÉng Gia Long hay Thi√™n Th·ªç LƒÉng (Â§©ÊéàÈôµ),...   \n",
            "5   M√¥ t·∫£: LƒÉng Minh M·∫°ng (hay c√≤n g·ªçi l√† Minh M·ªán...   \n",
            "6   M√¥ t·∫£: LƒÉng T·ª± ƒê·ª©c ( ch·ªØ H√°n : Âó£Âæ∑Èôµ) l√† m·ªôt qu·∫ß...   \n",
            "7   K·∫øt qu·∫£: Phong tr√†o th·∫•t b·∫°i. M√¥ t·∫£: Phong tr√†...   \n",
            "8   K·∫øt qu·∫£: C·∫£ 2 b√™n ƒë·ªÅu b·ªã thi·ªát h·∫°i n·∫∑ng Hoa K·ª≥...   \n",
            "9   K·∫øt qu·∫£: Ph√°p chi·∫øn th·∫Øng. M√¥ t·∫£: Tr·∫≠n C·ª≠a Thu...   \n",
            "10  K·∫øt qu·∫£: cu·ªôc n·ªïi d·∫≠y b·ªã d·∫≠p t·∫Øt. M√¥ t·∫£: V·ª• m∆∞...   \n",
            "\n",
            "                                           event_date  \\\n",
            "0                                                1601   \n",
            "1                                                1899   \n",
            "2                                                1802   \n",
            "3                                                None   \n",
            "4                                           1814-1820   \n",
            "5                                           1840-1841   \n",
            "6                                                1866   \n",
            "7                                                1885   \n",
            "8   ƒê·ª£t 1: 30-1 ƒë·∫øn 28-3, ƒê·ª£t 2: 5-5 ƒë·∫øn 15-6, ƒê·ª£t...   \n",
            "9                                    Th√°ng 8 nƒÉm 1883   \n",
            "10                                               1916   \n",
            "\n",
            "                                       event_location                 person  \n",
            "0   Vi·ªát Nam, Ph∆∞·ªùng H∆∞∆°ng Long , qu·∫≠n Ph√∫ Xu√¢n , ...           Nguy·ªÖn Ho√†ng  \n",
            "1   Vi·ªát Nam, Hu·∫ø, S√¥ng H∆∞∆°ng, 16¬∞28‚Ä≤08‚Ä≥B 107¬∞35‚Ä≤1...            H√£ng Eiffel  \n",
            "2                                            Ph√∫ Xu√¢n               Gia Long  \n",
            "3                                                                       None  \n",
            "4      Vi·ªát Nam, ph∆∞·ªùng Long H·ªì, qu·∫≠n Ph√∫ Xu√¢n, Hu·∫ø .               Gia Long  \n",
            "5                Vi·ªát Nam, Qu·∫ßn th·ªÉ di t√≠ch c·ªë ƒë√¥ Hu·∫ø  Minh M·∫°ng , Thi·ªáu Tr·ªã  \n",
            "6                Vi·ªát Nam, Qu·∫ßn th·ªÉ di t√≠ch c·ªë ƒë√¥ Hu·∫ø                 T·ª± ƒê·ª©c  \n",
            "7                  ‚Äì 1896, B·∫Øc K·ª≥ , Trung K·ª≥ , Nam K·ª≥                   None  \n",
            "8                                   mi·ªÅn Nam Vi·ªát Nam                   None  \n",
            "9                        g·∫ßn Hu·∫ø, mi·ªÅn trung Vi·ªát Nam                   None  \n",
            "10                 Kinh th√†nh Hu·∫ø v√† c√°c t·ªânh l√¢n c·∫≠n                   None  \n",
            "\n",
            "ƒê√£ l∆∞u file chu·∫©n h√≥a t·∫°i: /Users/thanhmai/etl_pipeline test/data/Wiki_Hue_chuyendoi.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/ry/f3gzj48x5_19ckmkh65zn1gh0000gn/T/ipykernel_4027/1453656481.py:65: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_clean = df_raw.groupby('T√™n trang').apply(transform_group).reset_index(drop=True)\n"
          ]
        }
      ],
      "source": [
        "DATE_ATTRS = [\n",
        "    'Kh·ªüi l·∫≠p', 'X√¢y d·ª±ng', 'Ng√†y x√¢y d·ª±ng', 'Th·ªùi gian', 'Ho√†n th√†nh'\n",
        "]\n",
        "PERSON_ATTRS = [\n",
        "    'Ng∆∞·ªùi s√°ng l·∫≠p', 'X√¢y d·ª±ng b·ªüi', 'X√¢y d·ª±ng\\xa0b·ªüi',\n",
        "    'Ng∆∞·ªùi x√¢y d·ª±ng', 'T·ªïng th·∫ßu'\n",
        "]\n",
        "LOCATION_ATTRS = [\n",
        "    'Qu·ªëc gia', 'ƒê·ªãa ch·ªâ', 'V·ªã tr√≠', 'ƒê·ªãa ƒëi·ªÉm', 'B·∫Øc qua', 'T·ªça ƒë·ªô'\n",
        "]\n",
        "DESCRIPTION_ATTRS = [\n",
        "    'M√¥ t·∫£','K·∫øt qu·∫£'\n",
        "]\n",
        "\n",
        "# --- 2. ƒê·ªåC FILE T·ª™ COLAB SESSION ---\n",
        "filepath = '/Users/thanhmai/etl_pipeline test/data/wiki_data_Hue.csv'\n",
        "\n",
        "try:\n",
        "    df_raw = pd.read_csv(filepath)\n",
        "    print(f\"--- ƒê√£ ƒë·ªçc file '{filepath}' th√†nh c√¥ng ---\")\n",
        "\n",
        "    # --- 3. ƒê·ªäNH NGHƒ®A H√ÄM BI·∫æN ƒê·ªîI CHU·∫®N H√ìA (ƒê√£ c·∫≠p nh·∫≠t) ---\n",
        "    def transform_group(group):\n",
        "        record = {\n",
        "            'event_name': group['T√™n trang'].iloc[0],\n",
        "            'description': [],\n",
        "            'event_date': None,\n",
        "            'event_location': [],\n",
        "            'person': None\n",
        "        }\n",
        "\n",
        "        for _, row in group.iterrows():\n",
        "            if 'Thu·ªôc t√≠nh' not in row or 'Gi√° tr·ªã' not in row:\n",
        "                continue\n",
        "\n",
        "            attr = str(row['Thu·ªôc t√≠nh'])\n",
        "            val = str(row['Gi√° tr·ªã'])\n",
        "            if attr in DATE_ATTRS:\n",
        "                match = re.match(r'(\\d+)\\s+(.*)', val)\n",
        "                if match:\n",
        "                    record['event_date'] = match.group(1) # '1802'\n",
        "                    record['event_location'].append(match.group(2)) # 'Ph√∫ Xu√¢n'\n",
        "                else:\n",
        "                    record['event_date'] = val\n",
        "\n",
        "            elif attr in PERSON_ATTRS:\n",
        "                record['person'] = val\n",
        "\n",
        "            elif attr in LOCATION_ATTRS:\n",
        "                record['event_location'].append(val)\n",
        "\n",
        "            elif attr in DESCRIPTION_ATTRS:\n",
        "                record['description'].append(f\"{attr}: {val}\")\n",
        "\n",
        "        record['description'] = \". \".join(record['description'])\n",
        "        record['event_location'] = \", \".join(record['event_location'])\n",
        "\n",
        "        return pd.Series(record)\n",
        "\n",
        "    # --- 4. √ÅP D·ª§NG H√ÄM BI·∫æN ƒê·ªîI ---\n",
        "    if 'T√™n trang' not in df_raw.columns:\n",
        "        print(\"L·ªñI: File c·ªßa b·∫°n kh√¥ng c√≥ c·ªôt 'T√™n trang'.\")\n",
        "        raise ValueError(\"Missing required column: 'T√™n trang'\")\n",
        "\n",
        "    df_clean = df_raw.groupby('T√™n trang').apply(transform_group).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "    print(\"--- D·ªÆ LI·ªÜU ƒê√É CHU·∫®N H√ìA (HO√ÄN CH·ªàNH) ---\")\n",
        "    print(df_clean)\n",
        "\n",
        "    # --- 5. L∆ØU FILE K·∫æT QU·∫¢ ---\n",
        "    output_filepath = \"/Users/thanhmai/etl_pipeline test/data/Wiki_Hue_chuyendoi.csv\"\n",
        "    df_clean.to_csv(output_filepath, index=False)\n",
        "    print(f\"\\nƒê√£ l∆∞u file chu·∫©n h√≥a t·∫°i: {output_filepath}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"L·ªñI: Kh√¥ng t√¨m th·∫•y file t√™n l√† '{filepath}'\")\n",
        "except Exception as e:\n",
        "    print(f\"ƒê√£ x·∫£y ra l·ªói khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1PPdFmGb0wF"
      },
      "source": [
        "C√°c l·ªÖ h·ªôi kh√°c kh√¥ng c√≥ tr√™n wiki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OHQ8pImYUhhe"
      },
      "outputs": [],
      "source": [
        "event_links = [\n",
        "    \"https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid/Le-hoi-Du-Tien.html/pid/14959/cid/198\",\n",
        "    \"https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid/Le-Hoi-Dien-Hon-Chen.html/pid/3036/cid/198\",\n",
        "    \"https://khamphahue.com.vn/Van-hoa/Chi-tiet/cid/198/pid/5780\",\n",
        "    \"https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid/Le-hoi-den-Huyen-Tran-Cong-chua.html/pid/1396/cid/198\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "M567qXJmZeHW"
      },
      "outputs": [],
      "source": [
        "def crawl_event_detail(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                      \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=20)\n",
        "        response.raise_for_status()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è L·ªói khi t·∫£i {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # --- T√™n s·ª± ki·ªán ---\n",
        "    title = soup.find(\"h1\").text.strip() if soup.find(\"h1\") else \"Kh√¥ng r√µ\"\n",
        "\n",
        "    # --- Th·ªùi gian ---\n",
        "    time_tag = soup.find(\"span\", id=\"dnn_ctr1099_ViewTinBai_DsChuyenMucTinBai_lblTableThoiGian\")\n",
        "    event_date = time_tag.text.strip() if time_tag else \"Kh√¥ng c√≥ th√¥ng tin th·ªùi gian\"\n",
        "\n",
        "    # --- ƒê·ªãa ch·ªâ ---\n",
        "    address_tag = soup.find(\"span\", id=\"dnn_ctr1099_ViewTinBai_DsChuyenMucTinBai_lblTableDiaChi\")\n",
        "    event_location = address_tag.text.strip() if address_tag else \"Kh√¥ng c√≥ th√¥ng tin ƒë·ªãa ch·ªâ\"\n",
        "\n",
        "    # --- M√î T·∫¢:\n",
        "    desc_box = soup.find(\"div\", id=\"dnn_ctr1099_ViewTinBai_DsChuyenMucTinBai_groupGioiThieu\")\n",
        "    content_box = soup.find(\"div\", class_=\"content-text-top\")\n",
        "\n",
        "    description = \"\"\n",
        "    if desc_box:\n",
        "        paragraphs = [p.get_text(\" \", strip=True) for p in desc_box.find_all(\"p\")]\n",
        "        description = \"\\n\".join(paragraphs)\n",
        "    elif content_box:\n",
        "        paragraphs = [p.get_text(\" \", strip=True) for p in content_box.find_all(\"p\")]\n",
        "        description = \"\\n\".join(paragraphs)\n",
        "    else:\n",
        "        description = \"Kh√¥ng c√≥ m√¥ t·∫£\"\n",
        "\n",
        "    return {\n",
        "        \"event_name\": title,\n",
        "        \"description\": description,\n",
        "        \"event_date\": event_date,\n",
        "        \"event_location\": event_location,\n",
        "        \"url\": url\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygcX3B8zbynu",
        "outputId": "323b959d-1b0d-4eda-df76-a3012be0e899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1/4) ƒêang crawl: https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid/Le-hoi-Du-Tien.html/pid/14959/cid/198\n",
            "(2/4) ƒêang crawl: https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid/Le-Hoi-Dien-Hon-Chen.html/pid/3036/cid/198\n",
            "(3/4) ƒêang crawl: https://khamphahue.com.vn/Van-hoa/Chi-tiet/cid/198/pid/5780\n",
            "(4/4) ƒêang crawl: https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid/Le-hoi-den-Huyen-Tran-Cong-chua.html/pid/1396/cid/198\n"
          ]
        }
      ],
      "source": [
        "all_events = []\n",
        "for i, link in enumerate(event_links, start=1):\n",
        "    print(f\"({i}/{len(event_links)}) ƒêang crawl: {link}\")\n",
        "    data = crawl_event_detail(link)\n",
        "    if data:\n",
        "        all_events.append(data)\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N1BVZMRb7Kt",
        "outputId": "41a44e10-27b0-44c0-fb1e-5b40bb25c7ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ƒê√£ crawl xong v√† l∆∞u v√†o hue_festivals.csv\n",
            "                        event_name  \\\n",
            "0                   L·ªÖ h·ªôi ƒêu Ti√™n   \n",
            "1             L·ªÖ H·ªôi ƒêi·ªán H√≤n Ch√©n   \n",
            "2                     L·ªÖ t·∫ø X√£ T·∫Øc   \n",
            "3  L·ªÖ h·ªôi ƒë·ªÅn Huy·ªÅn Tr√¢n C√¥ng ch√∫a   \n",
            "\n",
            "                                         description  \\\n",
            "0  L·ªÖ h·ªôi ƒêu Ti√™n th√¥n Gia Vi√™n, x√£ Phong Hi·ªÅn, h...   \n",
            "1  L·ªÖ h·ªôi ƒêi·ªán Hu·ªá Nam l√† l·ªÖ h·ªôi d√¢n gian truy·ªÅn ...   \n",
            "2  V√†o th·ªùi nh√† Nguy·ªÖn, L·ªÖ t·∫ø X√£ T·∫Øc l√† m·ªôt trong...   \n",
            "3  L·ªÖ h·ªôi ƒë·ªÅn Huy·ªÅn Tr√¢n C√¥ng ch√∫a l√† m·ªôt ho·∫°t ƒë·ªô...   \n",
            "\n",
            "                                event_date  \\\n",
            "0                       M√πng 4 T·∫øt √Çm l·ªãch   \n",
            "1  ƒê·∫ßu th√°ng 3 v√† th√°ng 7 √Çm l·ªãch h√†ng nƒÉm   \n",
            "2                    Cu·ªëi th√°ng 02 √Çm l·ªãch   \n",
            "3             M·ªìng 9 th√°ng Gi√™ng (√Çm l·ªãch)   \n",
            "\n",
            "                                      event_location  \\\n",
            "0  ƒê√¨nh l√†ng Gia Vi√™n, x√£ Phong Hi·ªÅn, huy·ªán Phong...   \n",
            "1        L√†ng H·∫£i C√°t, ph∆∞·ªùng Long H·ªì, th√†nh ph·ªë Hu·∫ø   \n",
            "2       ƒê√†n X√£ T·∫Øc (ph∆∞·ªùng Thu·∫≠n H√≤a, th√†nh ph·ªë Hu·∫ø)   \n",
            "3              151 Thi√™n Thai, An T√¢y, th√†nh ph·ªë Hu·∫ø   \n",
            "\n",
            "                                                 url  \n",
            "0  https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid...  \n",
            "1  https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid...  \n",
            "2  https://khamphahue.com.vn/Van-hoa/Chi-tiet/cid...  \n",
            "3  https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(all_events)\n",
        "df.to_csv(\"/Users/thanhmai/etl_pipeline test/data/hue_festivals.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"‚úÖ ƒê√£ crawl xong v√† l∆∞u v√†o hue_festivals.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qCVAQh663my"
      },
      "source": [
        "event ƒê√† N·∫µng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bGMR2j9Z68ls"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://vi.wikipedia.org/wiki/Tr%E1%BA%ADn_%C4%90%C3%A0_N%E1%BA%B5ng_(1859%E2%80%931860)\",\n",
        "    \"https://vi.wikipedia.org/wiki/Chi%E1%BA%BFn_d%E1%BB%8Bch_Hu%E1%BA%BF_%E2%80%93_%C4%90%C3%A0_N%E1%BA%B5ng\",\n",
        "    \"https://vi.wikipedia.org/wiki/B%C3%A0_N%C3%A0\",\n",
        "    \"https://vi.wikipedia.org/wiki/Ch%C3%B9a_Linh_%E1%BB%A8ng\",\n",
        "    \"https://vi.wikipedia.org/wiki/C%E1%BA%A7u_S%C3%B4ng_H%C3%A0n\",\n",
        "    \"https://vi.wikipedia.org/wiki/C%E1%BA%A7u_Tr%E1%BA%A7n_Th%E1%BB%8B_L%C3%BD\",\n",
        "    \"https://vi.wikipedia.org/wiki/C%E1%BA%A7u_R%E1%BB%93ng\",\n",
        "    \"https://vi.wikipedia.org/wiki/C%E1%BA%A7u_Thu%E1%BA%ADn_Ph%C6%B0%E1%BB%9Bc\"\n",
        "]\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "filepath = \"/Users/thanhmai/etl_pipeline test/data/wikipedia_data_DN.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ekrRJtGq6_dZ"
      },
      "outputs": [],
      "source": [
        "with open(filepath, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"T√™n trang\", \"Thu·ªôc t√≠nh\", \"Gi√° tr·ªã\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2U7ITT2r7BVh"
      },
      "outputs": [],
      "source": [
        "def crawl_wiki(url):\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    title_tag = soup.find(\"h1\", id=\"firstHeading\")\n",
        "    title = title_tag.text.strip() if title_tag else \"Kh√¥ng r√µ ti√™u ƒë·ªÅ\"\n",
        "    rows = []\n",
        "    # --- Crawl Infobox ---\n",
        "    infobox = soup.find(\"table\", class_=lambda x: x and \"infobox\" in x)\n",
        "    if infobox:\n",
        "        for row in infobox.find_all(\"tr\"):\n",
        "            label = row.find(\"th\")\n",
        "            value = row.find(\"td\")\n",
        "            if label and value:\n",
        "                key = label.get_text(\" \", strip=True)\n",
        "                val = value.get_text(\" \", strip=True)\n",
        "                rows.append([title, key, val])\n",
        "    # --- Crawl ph·∫ßn \"L·ªãch s·ª≠\" ho·∫∑c \"H√¨nh th√†nh\" ---\n",
        "    description = \"\"\n",
        "    for header in soup.find_all([\"h2\", \"h3\"]):\n",
        "        section_title = header.get_text(\" \", strip=True).lower()\n",
        "        if any(keyword in section_title for keyword in [\"l·ªãch s·ª≠\", \"h√¨nh th√†nh\", \"kh·ªüi l·∫≠p\", \"qu√° tr√¨nh x√¢y d·ª±ng\"]):\n",
        "            content = []\n",
        "            for sibling in header.find_next_siblings():\n",
        "                if sibling.name in [\"h2\", \"h3\"]:\n",
        "                    break\n",
        "                if sibling.name == \"p\":\n",
        "                    content.append(sibling.get_text(\" \", strip=True))\n",
        "            description = \"\\n\".join(content).strip()\n",
        "            break\n",
        "    if not description and infobox:\n",
        "        first_p_after_infobox = None\n",
        "        # L·∫∑p qua c√°c th·∫ª sau infobox ƒë·ªÉ t√¨m th·∫ª <p> ƒë·∫ßu ti√™n\n",
        "        for sibling in infobox.find_next_siblings():\n",
        "            if sibling.name == 'p':\n",
        "                first_p_after_infobox = sibling\n",
        "                break\n",
        "        if first_p_after_infobox:\n",
        "            description = first_p_after_infobox.get_text(\" \", strip=True)\n",
        "    if not description:\n",
        "        first_p = soup.find(\"p\")\n",
        "        if first_p:\n",
        "            description = first_p.get_text(\" \", strip=True)\n",
        "\n",
        "    for j in range(1, 500):\n",
        "        description = description.replace(f\"[{j}]\", \"\")\n",
        "    # Ghi d·ªØ li·ªáu\n",
        "    rows.append([title, \"M√¥ t·∫£\", description])\n",
        "    with open(filepath, \"a\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(rows)\n",
        "    print(f\"‚úÖ ƒê√£ l∆∞u {title} ({len(rows)} d√≤ng).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyAzrwV57D67",
        "outputId": "9b5d6ea3-0eb0-4d80-c8b4-7a9aabdcb2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ƒê√£ l∆∞u Tr·∫≠n ƒê√† N·∫µng (1859‚Äì1860) (5 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u Chi·∫øn d·ªãch Hu·∫ø ‚Äì ƒê√† N·∫µng (5 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u B√† N√† (1 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u Ch√πa Linh ·ª®ng (6 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u C·∫ßu S√¥ng H√†n (12 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u C·∫ßu Tr·∫ßn Th·ªã L√Ω (12 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u C·∫ßu R·ªìng (11 d√≤ng).\n",
            "‚úÖ ƒê√£ l∆∞u C·∫ßu Thu·∫≠n Ph∆∞·ªõc (12 d√≤ng).\n",
            "\n",
            "üéâ Ho√†n t·∫•t! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u trong file: /Users/thanhmai/etl_pipeline test/data/wikipedia_data_DN.csv\n"
          ]
        }
      ],
      "source": [
        "for url in urls:\n",
        "    try:\n",
        "        crawl_wiki(url)\n",
        "        time.sleep(2)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå L·ªói khi crawl {url}: {e}\")\n",
        "\n",
        "print(f\"\\nüéâ Ho√†n t·∫•t! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u trong file: {filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxBiAGx57JXA",
        "outputId": "fbb1f159-7ce9-4899-e9a7-4a51cf9fdd67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ƒê·ªçc file th√†nh c√¥ng! S·ªë d√≤ng: 64\n",
            "\n",
            "‚úÖ ƒê√£ l∆∞u file chu·∫©n h√≥a t·∫°i: /Users/thanhmai/etl_pipeline test/data/wikipedia_data_DN_clean.csv\n",
            "                 event_name  \\\n",
            "0                     B√† N√†   \n",
            "1  Chi·∫øn d·ªãch Hu·∫ø ‚Äì ƒê√† N·∫µng   \n",
            "2             Ch√πa Linh ·ª®ng   \n",
            "3                  C·∫ßu R·ªìng   \n",
            "4              C·∫ßu S√¥ng H√†n   \n",
            "5           C·∫ßu Thu·∫≠n Ph∆∞·ªõc   \n",
            "6           C·∫ßu Tr·∫ßn Th·ªã L√Ω   \n",
            "7  Tr·∫≠n ƒê√† N·∫µng (1859‚Äì1860)   \n",
            "\n",
            "                                         description            event_date  \\\n",
            "0  B√† N√† l√† khu b·∫£o t·ªìn thi√™n nhi√™n ƒë·ªìng th·ªùi c≈©n...                  None   \n",
            "1  Chi·∫øn th·∫Øng quy·∫øt ƒë·ªãnh c·ªßa Qu√¢n Gi·∫£i ph√≥ng mi·ªÅ...                  None   \n",
            "2  Ch√πa Linh ·ª®ng ( ch·ªØ H√°n : ÈùàÊáâÂØ∫) ‚Äì B√£i B·ª•t, S∆°n ...                  None   \n",
            "3  C·∫ßu R·ªìng l√† c√¢y c·∫ßu th·ª© 6 v√† l√† c√¢y c·∫ßu m·ªõi nh...                  2009   \n",
            "4  C·∫ßu S√¥ng H√†n l√† m·ªôt trong nh·ªØng c√¢y c·∫ßu b·∫Øc qu...  2/9/1998 - 29/3/2000   \n",
            "5  C·∫ßu Thu·∫≠n Ph∆∞·ªõc l√† c√¢y c·∫ßu treo d√¢y v√µng b·∫Øc q...             30/4/2005   \n",
            "6  C·∫ßu Tr·∫ßn Th·ªã L√Ω l√† c√¢y c·∫ßu b·∫Øc qua s√¥ng H√†n ·ªü ...   4/ 2009 - 29/3/2013   \n",
            "7  Li√™n qu√¢n Ph√°p - T√¢y Ban Nha r√∫t kh·ªèi ƒê√† N·∫µng ...                  None   \n",
            "\n",
            "                                      event_location  \\\n",
            "0                                                      \n",
            "1  Hu·∫ø , ƒê√† N·∫µng v√† c√°c t·ªânh Trung Trung B·ªô mi·ªÅn ...   \n",
            "2                                                      \n",
            "3  ƒê√† N·∫µng, s√¥ng H√†n, 16¬∞03‚Ä≤40‚Ä≥B 108¬∞13‚Ä≤36‚Ä≥ƒê Ôªø / ...   \n",
            "4  ƒê√† N·∫µng, S√¥ng H√†n, 16¬∞04‚Ä≤20‚Ä≥B 108¬∞13‚Ä≤36‚Ä≥ƒê Ôªø / ...   \n",
            "5  ƒê√† N·∫µng , Vi·ªát Nam, S√¥ng H√†n, 16¬∞05‚Ä≤31‚Ä≥B 108¬∞1...   \n",
            "6  ƒê√† N·∫µng, S√¥ng H√†n, 16¬∞03‚Ä≤01‚Ä≥B 108¬∞13‚Ä≤46‚Ä≥ƒê Ôªø / ...   \n",
            "7                                            ƒê√† N·∫µng   \n",
            "\n",
            "                                              person  \n",
            "0                                               None  \n",
            "1                                               None  \n",
            "2                                               None  \n",
            "3  + G√≥i 1A (c·∫ßu d·∫´n v√† CKN c·∫ßu ch√≠nh: Li√™n danh ...  \n",
            "4                 C√¥ng ty C·∫ßu 12 (CIENCO1) TECCO 533  \n",
            "5  C√¥ng ty C∆° kh√≠ x√¢y d·ª±ng c√¥ng tr√¨nh 623 v√† T·ªïng...  \n",
            "6  CIENCO 1 - C√¥ng ty VSL Vi·ªát Nam - C√¥ng ty CP T...  \n",
            "7                                               None  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/ry/f3gzj48x5_19ckmkh65zn1gh0000gn/T/ipykernel_4027/2135478392.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_clean = df.groupby('T√™n trang').apply(transform_group).reset_index(drop=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# === 1. ƒê·ªçc file g·ªëc ===\n",
        "file_path = \"/Users/thanhmai/etl_pipeline test/data/wikipedia_data_DN.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"‚úÖ ƒê·ªçc file th√†nh c√¥ng! S·ªë d√≤ng:\", len(df))\n",
        "\n",
        "# === 2. ƒê·ªãnh nghƒ©a nh√≥m thu·ªôc t√≠nh ===\n",
        "DATE_START_ATTRS = ['Th·ªùi gian kh·ªüi c√¥ng', 'Kh·ªüi c√¥ng']\n",
        "DATE_END_ATTRS = ['Th·ªùi gian ho√†n th√†nh', 'Ho√†n th√†nh', 'Th√¥ng xe']\n",
        "LOCATION_ATTRS = ['ƒê·ªãa ƒëi·ªÉm', 'V·ªã tr√≠', 'B·∫Øc qua', 'T·ªça ƒë·ªô']\n",
        "PERSON_ATTRS = ['Ng∆∞·ªùi thi·∫øt k·∫ø', 'Ng∆∞·ªùi s√°ng l·∫≠p', 'X√¢y d·ª±ng b·ªüi', 'T·ªïng th·∫ßu']\n",
        "DESCRIPTION_ATTRS = ['M√¥ t·∫£', 'K·∫øt qu·∫£', 'Th√¥ng tin']\n",
        "\n",
        "def normalize_date(text):\n",
        "    text = str(text).strip()\n",
        "    text = re.sub(r'(\\d{1,2})\\s*th√°ng\\s*(\\d{1,2})\\s*nƒÉm\\s*(\\d{4})', r'\\1/\\2/\\3', text)\n",
        "    text = re.sub(r'(\\d{1,2})\\s*/\\s*(\\d{1,2})\\s*/\\s*(\\d{4})', r'\\1/\\2/\\3', text)\n",
        "    return text if text else None\n",
        "\n",
        "def transform_group(group):\n",
        "    record = {\n",
        "        'event_name': group['T√™n trang'].iloc[0],\n",
        "        'description': [],\n",
        "        'event_date_start': None,\n",
        "        'event_date_end': None,\n",
        "        'event_location': [],\n",
        "        'person': None\n",
        "    }\n",
        "\n",
        "    for _, row in group.iterrows():\n",
        "        attr = str(row['Thu·ªôc t√≠nh']).strip()\n",
        "        val = str(row['Gi√° tr·ªã']).strip()\n",
        "\n",
        "        val_normalized = normalize_date(val)\n",
        "\n",
        "        if attr in DATE_START_ATTRS and val_normalized:\n",
        "            record['event_date_start'] = val_normalized\n",
        "        elif attr in DATE_END_ATTRS and val_normalized:\n",
        "            record['event_date_end'] = val_normalized\n",
        "        elif attr in LOCATION_ATTRS:\n",
        "            record['event_location'].append(val)\n",
        "        elif attr in PERSON_ATTRS:\n",
        "            record['person'] = val\n",
        "        elif attr in DESCRIPTION_ATTRS:\n",
        "            val = re.sub(r'^(M√¥ t·∫£|K·∫øt qu·∫£|Th√¥ng tin)\\s*:\\s*', '', val)\n",
        "            record['description'].append(val)\n",
        "\n",
        "    record['event_location'] = \", \".join(record['event_location'])\n",
        "    record['description'] = \". \".join(record['description'])\n",
        "\n",
        "    # G·ªôp ng√†y kh·ªüi c√¥ng v√† ho√†n th√†nh\n",
        "    if record['event_date_start'] and record['event_date_end']:\n",
        "        record['event_date'] = f\"{record['event_date_start']} - {record['event_date_end']}\"\n",
        "    elif record['event_date_start']:\n",
        "        record['event_date'] = record['event_date_start']\n",
        "    elif record['event_date_end']:\n",
        "        record['event_date'] = record['event_date_end']\n",
        "    else:\n",
        "        record['event_date'] = None\n",
        "\n",
        "    return pd.Series({\n",
        "        'event_name': record['event_name'],\n",
        "        'description': record['description'],\n",
        "        'event_date': record['event_date'],\n",
        "        'event_location': record['event_location'],\n",
        "        'person': record['person']\n",
        "    })\n",
        "\n",
        "# === 5. Gom nh√≥m theo T√™n trang ===\n",
        "df_clean = df.groupby('T√™n trang').apply(transform_group).reset_index(drop=True)\n",
        "\n",
        "# === 6. Xu·∫•t k·∫øt qu·∫£ ===\n",
        "output_file = \"/Users/thanhmai/etl_pipeline test/data/wikipedia_data_DN_clean.csv\"\n",
        "df_clean.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"\\n‚úÖ ƒê√£ l∆∞u file chu·∫©n h√≥a t·∫°i: {output_file}\")\n",
        "print(df_clean.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rogiqAEM7W7a",
        "outputId": "0a00f934-8839-4505-95b4-3e9592cada46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         event_name  \\\n",
            "0                     Ch√πa Thi√™n M·ª•   \n",
            "1                   C·∫ßu Tr∆∞·ªùng Ti·ªÅn   \n",
            "2                         C·ªë ƒë√¥ Hu·∫ø   \n",
            "3                      Festival Hu·∫ø   \n",
            "4                     LƒÉng Gia Long   \n",
            "5                    LƒÉng Minh M·∫°ng   \n",
            "6                       LƒÉng T·ª± ƒê·ª©c   \n",
            "7              Phong tr√†o C·∫ßn V∆∞∆°ng   \n",
            "8              S·ª± ki·ªán T·∫øt M·∫≠u Th√¢n   \n",
            "9                 Tr·∫≠n C·ª≠a Thu·∫≠n An   \n",
            "10   V·ª• m∆∞u kh·ªüi nghƒ©a ·ªü Hu·∫ø (1916)   \n",
            "11                   L·ªÖ h·ªôi ƒêu Ti√™n   \n",
            "12             L·ªÖ H·ªôi ƒêi·ªán H√≤n Ch√©n   \n",
            "13                     L·ªÖ t·∫ø X√£ T·∫Øc   \n",
            "14  L·ªÖ h·ªôi ƒë·ªÅn Huy·ªÅn Tr√¢n C√¥ng ch√∫a   \n",
            "15                            B√† N√†   \n",
            "16         Chi·∫øn d·ªãch Hu·∫ø ‚Äì ƒê√† N·∫µng   \n",
            "17                    Ch√πa Linh ·ª®ng   \n",
            "18                         C·∫ßu R·ªìng   \n",
            "19                     C·∫ßu S√¥ng H√†n   \n",
            "20                  C·∫ßu Thu·∫≠n Ph∆∞·ªõc   \n",
            "21                  C·∫ßu Tr·∫ßn Th·ªã L√Ω   \n",
            "22         Tr·∫≠n ƒê√† N·∫µng (1859‚Äì1860)   \n",
            "\n",
            "                                          description  \\\n",
            "0   M√¥ t·∫£: Ch√πa Thi√™n M·ª• hay c√≤n g·ªçi l√† ch√πa Linh ...   \n",
            "1   M√¥ t·∫£: C·∫ßu Tr∆∞·ªùng Ti·ªÅn hay c·∫ßu Tr√†ng Ti·ªÅn [ 1 ...   \n",
            "2   M√¥ t·∫£: C·ªë ƒë√¥ Hu·∫ø , c√≤n g·ªçi l√† Ph√∫ Xu√¢n , l√† th...   \n",
            "3   M√¥ t·∫£: Festival Hu·∫ø ƒë∆∞·ª£c t·ªï ch·ª©c 2 nƒÉm m·ªôt l·∫ßn...   \n",
            "4   M√¥ t·∫£: LƒÉng Gia Long hay Thi√™n Th·ªç LƒÉng (Â§©ÊéàÈôµ),...   \n",
            "5   M√¥ t·∫£: LƒÉng Minh M·∫°ng (hay c√≤n g·ªçi l√† Minh M·ªán...   \n",
            "6   M√¥ t·∫£: LƒÉng T·ª± ƒê·ª©c ( ch·ªØ H√°n : Âó£Âæ∑Èôµ) l√† m·ªôt qu·∫ß...   \n",
            "7   K·∫øt qu·∫£: Phong tr√†o th·∫•t b·∫°i. M√¥ t·∫£: Phong tr√†...   \n",
            "8   K·∫øt qu·∫£: C·∫£ 2 b√™n ƒë·ªÅu b·ªã thi·ªát h·∫°i n·∫∑ng Hoa K·ª≥...   \n",
            "9   K·∫øt qu·∫£: Ph√°p chi·∫øn th·∫Øng. M√¥ t·∫£: Tr·∫≠n C·ª≠a Thu...   \n",
            "10  K·∫øt qu·∫£: cu·ªôc n·ªïi d·∫≠y b·ªã d·∫≠p t·∫Øt. M√¥ t·∫£: V·ª• m∆∞...   \n",
            "11  L·ªÖ h·ªôi ƒêu Ti√™n th√¥n Gia Vi√™n, x√£ Phong Hi·ªÅn, h...   \n",
            "12  L·ªÖ h·ªôi ƒêi·ªán Hu·ªá Nam l√† l·ªÖ h·ªôi d√¢n gian truy·ªÅn ...   \n",
            "13  V√†o th·ªùi nh√† Nguy·ªÖn, L·ªÖ t·∫ø X√£ T·∫Øc l√† m·ªôt trong...   \n",
            "14  L·ªÖ h·ªôi ƒë·ªÅn Huy·ªÅn Tr√¢n C√¥ng ch√∫a l√† m·ªôt ho·∫°t ƒë·ªô...   \n",
            "15  B√† N√† l√† khu b·∫£o t·ªìn thi√™n nhi√™n ƒë·ªìng th·ªùi c≈©n...   \n",
            "16  Chi·∫øn th·∫Øng quy·∫øt ƒë·ªãnh c·ªßa Qu√¢n Gi·∫£i ph√≥ng mi·ªÅ...   \n",
            "17  Ch√πa Linh ·ª®ng ( ch·ªØ H√°n : ÈùàÊáâÂØ∫) ‚Äì B√£i B·ª•t, S∆°n ...   \n",
            "18  C·∫ßu R·ªìng l√† c√¢y c·∫ßu th·ª© 6 v√† l√† c√¢y c·∫ßu m·ªõi nh...   \n",
            "19  C·∫ßu S√¥ng H√†n l√† m·ªôt trong nh·ªØng c√¢y c·∫ßu b·∫Øc qu...   \n",
            "20  C·∫ßu Thu·∫≠n Ph∆∞·ªõc l√† c√¢y c·∫ßu treo d√¢y v√µng b·∫Øc q...   \n",
            "21  C·∫ßu Tr·∫ßn Th·ªã L√Ω l√† c√¢y c·∫ßu b·∫Øc qua s√¥ng H√†n ·ªü ...   \n",
            "22  Li√™n qu√¢n Ph√°p - T√¢y Ban Nha r√∫t kh·ªèi ƒê√† N·∫µng ...   \n",
            "\n",
            "                                           event_date  \\\n",
            "0                                                1601   \n",
            "1                                                1899   \n",
            "2                                                1802   \n",
            "3                                                 NaN   \n",
            "4                                           1814-1820   \n",
            "5                                           1840-1841   \n",
            "6                                                1866   \n",
            "7                                                1885   \n",
            "8   ƒê·ª£t 1: 30-1 ƒë·∫øn 28-3, ƒê·ª£t 2: 5-5 ƒë·∫øn 15-6, ƒê·ª£t...   \n",
            "9                                    Th√°ng 8 nƒÉm 1883   \n",
            "10                                               1916   \n",
            "11                                 M√πng 4 T·∫øt √Çm l·ªãch   \n",
            "12            ƒê·∫ßu th√°ng 3 v√† th√°ng 7 √Çm l·ªãch h√†ng nƒÉm   \n",
            "13                              Cu·ªëi th√°ng 02 √Çm l·ªãch   \n",
            "14                       M·ªìng 9 th√°ng Gi√™ng (√Çm l·ªãch)   \n",
            "15                                                NaN   \n",
            "16                                                NaN   \n",
            "17                                                NaN   \n",
            "18                                               2009   \n",
            "19                               2/9/1998 - 29/3/2000   \n",
            "20                                          30/4/2005   \n",
            "21                                4/ 2009 - 29/3/2013   \n",
            "22                                                NaN   \n",
            "\n",
            "                                       event_location  \\\n",
            "0   Vi·ªát Nam, Ph∆∞·ªùng H∆∞∆°ng Long , qu·∫≠n Ph√∫ Xu√¢n , ...   \n",
            "1   Vi·ªát Nam, Hu·∫ø, S√¥ng H∆∞∆°ng, 16¬∞28‚Ä≤08‚Ä≥B 107¬∞35‚Ä≤1...   \n",
            "2                                            Ph√∫ Xu√¢n   \n",
            "3                                                 NaN   \n",
            "4      Vi·ªát Nam, ph∆∞·ªùng Long H·ªì, qu·∫≠n Ph√∫ Xu√¢n, Hu·∫ø .   \n",
            "5                Vi·ªát Nam, Qu·∫ßn th·ªÉ di t√≠ch c·ªë ƒë√¥ Hu·∫ø   \n",
            "6                Vi·ªát Nam, Qu·∫ßn th·ªÉ di t√≠ch c·ªë ƒë√¥ Hu·∫ø   \n",
            "7                  ‚Äì 1896, B·∫Øc K·ª≥ , Trung K·ª≥ , Nam K·ª≥   \n",
            "8                                   mi·ªÅn Nam Vi·ªát Nam   \n",
            "9                        g·∫ßn Hu·∫ø, mi·ªÅn trung Vi·ªát Nam   \n",
            "10                 Kinh th√†nh Hu·∫ø v√† c√°c t·ªânh l√¢n c·∫≠n   \n",
            "11  ƒê√¨nh l√†ng Gia Vi√™n, x√£ Phong Hi·ªÅn, huy·ªán Phong...   \n",
            "12        L√†ng H·∫£i C√°t, ph∆∞·ªùng Long H·ªì, th√†nh ph·ªë Hu·∫ø   \n",
            "13       ƒê√†n X√£ T·∫Øc (ph∆∞·ªùng Thu·∫≠n H√≤a, th√†nh ph·ªë Hu·∫ø)   \n",
            "14              151 Thi√™n Thai, An T√¢y, th√†nh ph·ªë Hu·∫ø   \n",
            "15                                                NaN   \n",
            "16  Hu·∫ø , ƒê√† N·∫µng v√† c√°c t·ªânh Trung Trung B·ªô mi·ªÅn ...   \n",
            "17                                                NaN   \n",
            "18  ƒê√† N·∫µng, s√¥ng H√†n, 16¬∞03‚Ä≤40‚Ä≥B 108¬∞13‚Ä≤36‚Ä≥ƒê Ôªø / ...   \n",
            "19  ƒê√† N·∫µng, S√¥ng H√†n, 16¬∞04‚Ä≤20‚Ä≥B 108¬∞13‚Ä≤36‚Ä≥ƒê Ôªø / ...   \n",
            "20  ƒê√† N·∫µng , Vi·ªát Nam, S√¥ng H√†n, 16¬∞05‚Ä≤31‚Ä≥B 108¬∞1...   \n",
            "21  ƒê√† N·∫µng, S√¥ng H√†n, 16¬∞03‚Ä≤01‚Ä≥B 108¬∞13‚Ä≤46‚Ä≥ƒê Ôªø / ...   \n",
            "22                                            ƒê√† N·∫µng   \n",
            "\n",
            "                                               person  \\\n",
            "0                                        Nguy·ªÖn Ho√†ng   \n",
            "1                                         H√£ng Eiffel   \n",
            "2                                            Gia Long   \n",
            "3                                                 NaN   \n",
            "4                                            Gia Long   \n",
            "5                               Minh M·∫°ng , Thi·ªáu Tr·ªã   \n",
            "6                                              T·ª± ƒê·ª©c   \n",
            "7                                                 NaN   \n",
            "8                                                 NaN   \n",
            "9                                                 NaN   \n",
            "10                                                NaN   \n",
            "11                                                NaN   \n",
            "12                                                NaN   \n",
            "13                                                NaN   \n",
            "14                                                NaN   \n",
            "15                                                NaN   \n",
            "16                                                NaN   \n",
            "17                                                NaN   \n",
            "18  + G√≥i 1A (c·∫ßu d·∫´n v√† CKN c·∫ßu ch√≠nh: Li√™n danh ...   \n",
            "19                 C√¥ng ty C·∫ßu 12 (CIENCO1) TECCO 533   \n",
            "20  C√¥ng ty C∆° kh√≠ x√¢y d·ª±ng c√¥ng tr√¨nh 623 v√† T·ªïng...   \n",
            "21  CIENCO 1 - C√¥ng ty VSL Vi·ªát Nam - C√¥ng ty CP T...   \n",
            "22                                                NaN   \n",
            "\n",
            "                                                  url  \n",
            "0                                                 NaN  \n",
            "1                                                 NaN  \n",
            "2                                                 NaN  \n",
            "3                                                 NaN  \n",
            "4                                                 NaN  \n",
            "5                                                 NaN  \n",
            "6                                                 NaN  \n",
            "7                                                 NaN  \n",
            "8                                                 NaN  \n",
            "9                                                 NaN  \n",
            "10                                                NaN  \n",
            "11  https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid...  \n",
            "12  https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid...  \n",
            "13  https://khamphahue.com.vn/Van-hoa/Chi-tiet/cid...  \n",
            "14  https://khamphahue.com.vn/Van-hoa/Chi-tiet/tid...  \n",
            "15                                                NaN  \n",
            "16                                                NaN  \n",
            "17                                                NaN  \n",
            "18                                                NaN  \n",
            "19                                                NaN  \n",
            "20                                                NaN  \n",
            "21                                                NaN  \n",
            "22                                                NaN  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. ƒê·ªçc 2 file (ho·∫∑c nhi·ªÅu h∆°n)\n",
        "df1 = pd.read_csv(f\"/Users/thanhmai/etl_pipeline test/data/Wiki_Hue_chuyendoi.csv\")\n",
        "df2 = pd.read_csv(\"/Users/thanhmai/etl_pipeline test/data/hue_festivals.csv\")\n",
        "df3 = pd.read_csv(\"/Users/thanhmai/etl_pipeline test/data/wikipedia_data_DN_clean.csv\")\n",
        "\n",
        "# 2. G·ªôp ch√∫ng l·∫°i th√†nh m·ªôt danh s√°ch\n",
        "danh_sach_dfs = [df1, df2,df3]\n",
        "\n",
        "# 3. D√πng pd.concat ƒë·ªÉ n·ªëi\n",
        "event_cap2 = pd.concat(danh_sach_dfs, ignore_index=True)\n",
        "print(event_cap2)\n",
        "\n",
        "# 5. L∆∞u file\n",
        "event_cap2.to_csv(\"/Users/thanhmai/etl_pipeline test/data/event_raw.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
